# 优化算法

总结比较常用的优化算法。

![](http://chenguanfuqq.gitee.io/tuquan2/img_2018_4/contours_evaluation_optimizers.gif)

![](http://chenguanfuqq.gitee.io/tuquan2/img_2018_4/saddle_point_evaluation_optimizers.gif)


---
## 相关论文
- ...

## 测试


## 实现

代码相关实现可以参考[pytorch sgd.py](https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py)

[PyTorch批训练及优化器比较](https://blog.csdn.net/marsjhao/article/details/72055310)

[ConvNetJS Trainer demo on MNIST](https://cs.stanford.edu/people/karpathy/convnetjs/demo/trainers.html)

[optimizing-gradient-descent](http://ruder.io/optimizing-gradient-descent/) 较为系统的介绍了各种梯度优化算法，同时有[中文版翻译](https://blog.csdn.net/google19890102/article/details/69942970)

[各种优化方法总结比较（sgd/momentum/Nesterov/adagrad/adadelta）](https://blog.csdn.net/luo123n/article/details/48239963)

[关于BP算法在DNN中本质问题的几点随笔](http://www.cnblogs.com/matthewbai/p/4126551.html)

[Optimization: Stochastic Gradient Descent](http://ufldl.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/)

[Deep Learning 优化方法总结](http://yufeigan.github.io/2014/11/29/Deep-Learning-%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/) 简洁明了，对常见的优化算法公式进行了备注，同时记录了这些算法的优缺点。

cs231 Lecture 3: Loss Functions and Optimization

[Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f) 不仅仅罗列了算法，同时对各种算法的优缺点进行了介绍
