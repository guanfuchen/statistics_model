{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('../data/rnn/shakespear.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique_chars = list(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size, X_size = len(data), len(data_unique_chars) # one-hot编码长度和数据大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字典转换char到相应的索引\n",
    "char_to_idx = {ch:i for i,ch in enumerate(data_unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字典转换索引到相应的char\n",
    "idx_to_char = {i:ch for i,ch in enumerate(data_unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    sigmoid_out = 1/(1+np.exp(-x))\n",
    "    return sigmoid_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigmoid(y):\n",
    "    # 使用输出值\n",
    "    dsigmoid_out = y*(1-y)\n",
    "    \n",
    "    return dsigmoid_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    tanh_out = np.tanh(x)\n",
    "    return tanh_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtanh(y):\n",
    "    # 使用输出值\n",
    "    dtanh_out = 1-y*y\n",
    "    return dtanh_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x_exp = np.exp(x)\n",
    "    x_exp_sum = np.sum(x_exp)\n",
    "    return x_exp/x_exp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_std = 0.1 # 权重初始化标准差\n",
    "H_size = 100 # 隐藏层大小\n",
    "z_size = H_size+X_size # 隐藏层和数据层concatenate大小\n",
    "T_steps = 25 # 训练数据长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM每一个单独参数\n",
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.value = value # 参数值\n",
    "        self.name = name # 参数名\n",
    "        self.dvalue = np.zeros_like(self.value) # 参数梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        # sigmoid函数正态分布初始化(0.5,weight_std)，tanh函数正态分布初始化(0,weight_std)\n",
    "        self.W_f = Param('W_f', np.random.randn(H_size, z_size)*weight_std+0.5)\n",
    "        self.b_f = Param('b_f', np.zeros((H_size, 1)))\n",
    "        \n",
    "        self.W_i = Param('W_i', np.random.randn(H_size, z_size)*weight_std+0.5)\n",
    "        self.b_i = Param('b_i', np.zeros((H_size, 1)))\n",
    "        \n",
    "        self.W_C = Param('W_C', np.random.randn(H_size, z_size)*weight_std)\n",
    "        self.b_C = Param('b_C', np.zeros((H_size, 1)))\n",
    "        \n",
    "        self.W_o = Param('W_o', np.random.randn(H_size, z_size)*weight_std+0.5)\n",
    "        self.b_o = Param('b_o', np.zeros((H_size, 1)))\n",
    "        \n",
    "        # 输出层\n",
    "        self.W_v = Param('W_v', np.random.randn(X_size, H_size)*weight_std)\n",
    "        self.b_v = Param('b_v', np.zeros((X_size, 1)))\n",
    "        \n",
    "    def all(self):\n",
    "        return [self.W_f, self.b_f, self.W_i, self.b_i, self.W_C, self.b_C, self.W_o, self.b_o, self.W_v, self.b_v]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, h_prev, C_prev, p=parameters):\n",
    "    assert x.shape == (X_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    f = sigmoid(np.dot(p.W_f.value, z)+p.b_f.value)\n",
    "    i = sigmoid(np.dot(p.W_i.value, z)+p.b_i.value)\n",
    "    C_bar = tanh(np.dot(p.W_C.value, z)+p.b_C.value)\n",
    "    \n",
    "    C = f*C_prev + i*C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.value, z)+p.b_o.value)\n",
    "    h = o*tanh(C)\n",
    "    \n",
    "    v = np.dot(p.W_v.value, h)+p.b_v.value\n",
    "    y_bar = softmax(v)\n",
    "    \n",
    "    return z, f, i, C_bar, C, o, h, v, y_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = ([char_to_idx[ch] for ch in data[0:T_steps]])\n",
    "target_data = ([char_to_idx[ch] for ch in data[1:T_steps+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_data_len = 1\n",
    "# h = np.zeros((H_size, 1))\n",
    "# C = np.zeros((H_size, 1))\n",
    "h_data = np.zeros((T_steps+reduce_data_len, H_size, 1))\n",
    "C_data = np.zeros((T_steps+reduce_data_len, H_size, 1))\n",
    "theta_h_data = np.zeros((T_steps+reduce_data_len, H_size, 1))\n",
    "theta_C_data = np.zeros((T_steps+reduce_data_len, H_size, 1))\n",
    "z_data = np.zeros((T_steps, z_size, 1))\n",
    "f_data = np.zeros((T_steps, H_size, 1))\n",
    "i_data = np.zeros((T_steps, H_size, 1))\n",
    "C_bar_data = np.zeros((T_steps, H_size, 1))\n",
    "o_data = np.zeros((T_steps, H_size, 1))\n",
    "v_data = np.zeros((T_steps, X_size, 1))\n",
    "y_bar_data = np.zeros((T_steps, X_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(theta_h_data, theta_C_data, target_data, h_data, C_data, z_data, f_data, i_data, C_bar_data, o_data, v_data, y_bar_data, p=parameters):\n",
    "    # 学习率\n",
    "    lr = 0.0001\n",
    "    # 计算最后的误差\n",
    "    \n",
    "    y_T = target_data[T_steps-1]\n",
    "    y_one_hot_T = np.zeros((X_size, 1))\n",
    "    y_one_hot_T[y_T] = 1\n",
    "    error_T = y_one_hot_T-y_bar_data[T_steps-1]\n",
    "\n",
    "    theta_h_T = np.dot(np.transpose(parameters.W_v.value), error_T)\n",
    "    theta_C_T = theta_h_T * o_data[T_steps-1] * (1-np.power(np.tanh(C_data[reduce_data_len+T_steps-1]), 2))\n",
    "    theta_h_data[reduce_data_len+T_steps-1] = theta_h_T\n",
    "    theta_C_data[reduce_data_len+T_steps-1] = theta_C_T\n",
    "    # print(theta_h_T)\n",
    "    # 反向传播计算C和h\n",
    "    for t in range(T_steps-2, -1, -1):\n",
    "        y_t = target_data[t]\n",
    "        y_one_hot_t = np.zeros((X_size, 1))\n",
    "        y_one_hot_t[y_t] = 1\n",
    "        error_t = y_one_hot_t-y_bar_data[t]\n",
    "        theta_h_data[reduce_data_len+t] = np.dot(np.transpose(p.W_v.value), error_t)\n",
    "        theta_C_data[reduce_data_len+t] = theta_h_data[reduce_data_len+t] * o_data[t] * (1- np.power(np.tanh(C_data[reduce_data_len+t]), 2))+f_data[t+1]*theta_C_data[reduce_data_len+t+1]\n",
    "#         print('theta_C_data.shape:', theta_C_data.shape)\n",
    "    # 计算W和b的梯度\n",
    "    for t in range(1, T_steps, 1):\n",
    "        y_t = target_data[t]\n",
    "        y_one_hot_t = np.zeros((X_size, 1))\n",
    "        y_one_hot_t[y_t] = 1\n",
    "        error_t = y_one_hot_t-y_bar_data[t]\n",
    "        W_v_gradient_t = np.dot(error_t, np.transpose(h_data[reduce_data_len+t]))\n",
    "        b_v_gradient_t = error_t\n",
    "        p.W_v.value -= lr * W_v_gradient_t\n",
    "        p.b_v.value -= lr * b_v_gradient_t\n",
    "        \n",
    "        W_o_gradient_t = np.dot(theta_h_data[reduce_data_len+t]*np.tanh(C_data[reduce_data_len+t])*o_data[t]*(1-o_data[t]), np.transpose(z_data[t]))\n",
    "        b_o_gradient_t = theta_h_data[reduce_data_len+t]*np.tanh(C_data[reduce_data_len+t])*o_data[t]*(1-o_data[t])\n",
    "        p.W_o.value -= lr * W_o_gradient_t\n",
    "        p.b_o.value -= lr * b_o_gradient_t\n",
    "        \n",
    "        W_f_gradient_t = np.dot(theta_C_data[reduce_data_len+t]*np.tanh(C_data[reduce_data_len+t-1])*f_data[t]*(1-f_data[t]), np.transpose(z_data[t]))\n",
    "        b_f_gradient_t = theta_C_data[reduce_data_len+t]*np.tanh(C_data[reduce_data_len+t-1])*f_data[t]*(1-f_data[t])\n",
    "        p.W_f.value -= lr * W_f_gradient_t\n",
    "        p.b_f.value -= lr * b_f_gradient_t\n",
    "        \n",
    "        W_C_gradient_t = np.dot(theta_C_data[reduce_data_len+t]*i_data[t]*(1-np.power(np.tanh(C_bar_data[t]), 2)), np.transpose(z_data[t]))\n",
    "        b_C_gradient_t = theta_C_data[reduce_data_len+t]*i_data[t]*(1-np.power(np.tanh(C_bar_data[t]), 2))\n",
    "        p.W_C.value -= lr * W_C_gradient_t\n",
    "        p.b_C.value -= lr * b_C_gradient_t\n",
    "        \n",
    "        W_i_gradient_t = np.dot(theta_C_data[reduce_data_len+t]*i_data[t]*(1-i_data[t])*C_bar_data[t], np.transpose(z_data[t]))\n",
    "        b_i_gradient_t = theta_C_data[reduce_data_len+t]*i_data[t]*(1-i_data[t])*C_bar_data[t]\n",
    "        p.W_i.value -= lr * W_i_gradient_t\n",
    "        p.b_i.value -= lr * b_i_gradient_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss:', 103.29016184582763)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    # 前向传播\n",
    "    loss = 0\n",
    "    for t in range(T_steps):\n",
    "        x_t = input_data[t]\n",
    "        x_one_hot_t = np.zeros((X_size, 1))\n",
    "        x_one_hot_t[x_t] = 1\n",
    "        y_t = target_data[t]\n",
    "        y_one_hot_t = np.zeros((X_size, 1))\n",
    "        y_one_hot_t[y_t] = 1\n",
    "        z_t, f_t, i_t, C_bar_t, C_t, o_t, h_t, v_t, y_bar_t = forward(x_one_hot_t, h_data[(t+reduce_data_len)-1], C_data[(t+reduce_data_len)-1])\n",
    "        z_data[t] = z_t\n",
    "        f_data[t] = f_t\n",
    "        i_data[t] = i_t\n",
    "        C_bar_data[t] = C_bar_t\n",
    "        C_data[(t+reduce_data_len)] = C_t\n",
    "        o_data[t] = o_t\n",
    "        h_data[(t+reduce_data_len)] = h_t\n",
    "        v_data[t] = v_t\n",
    "        y_bar_data[t] = y_bar_t\n",
    "        loss += -np.sum(y_one_hot_t*np.log(y_bar_data[t]))\n",
    "    # 反向传播\n",
    "    backward(theta_h_data, theta_C_data, target_data, h_data, C_data, z_data, f_data, i_data, C_bar_data, o_data, v_data, y_bar_data, p=parameters)\n",
    "print('loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
